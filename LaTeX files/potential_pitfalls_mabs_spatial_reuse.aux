\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{abbrvnat}
\providecommand \oddpage@label [2]{}
\Newlabel{cor1}{1}
\Newlabel{label1}{a}
\Newlabel{label2}{b}
\Newlabel{label3}{c}
\citation{bellalta2016ax}
\citation{ergin2007understanding}
\citation{smith2015dynamic}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}}
\newlabel{section:introduction}{{1}{2}{Introduction}{section.1}{}}
\citation{chen2010distributed,maghsudi2015channel,maghsudi2015joint}
\citation{bellalta2017throughput}
\citation{nie1999q}
\citation{li2009multi,bennis2010q,bennis2011distributed,sallent2015learning,rupasinghe2015reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{4}{section.2}}
\newlabel{section:previous_work}{{2}{4}{Related Work}{section.2}{}}
\citation{liu2010distributed,anandkumar2011distributed,rosenski2016multi,maghsudi2015joint,maghsudi2015channel}
\citation{liu2010distributed}
\citation{anandkumar2011distributed}
\citation{anandkumar2011distributed}
\citation{rosenski2016multi}
\citation{rosenski2016multi}
\citation{maghsudi2015joint,maghsudi2015channel}
\citation{maghsudi2015joint}
\citation{maghsudi2015joint}
\citation{maghsudi2015channel}
\@writefile{toc}{\contentsline {section}{\numberline {3}Interactions between WLANs when Spatial Reuse is Enabled}{6}{section.3}}
\newlabel{section:interactions_wlans}{{3}{6}{Interactions between WLANs when Spatial Reuse is Enabled}{section.3}{}}
\citation{barrachina2018performance}
\citation{barrachina2018overlap}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}CSMA/CA}{7}{subsection.3.1}}
\newlabel{section:csma}{{3.1}{7}{CSMA/CA}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}CSMA/CA Throughput Model}{7}{subsection.3.2}}
\newlabel{section:throughput_model}{{3.2}{7}{CSMA/CA Throughput Model}{subsection.3.2}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:csma_a}{{1(a)}{8}{Scenario\relax }{figure.caption.1}{}}
\newlabel{sub@fig:csma_a}{{(a)}{8}{Scenario\relax }{figure.caption.1}{}}
\newlabel{fig:csma_b}{{1(b)}{8}{CSMA/CA operation\relax }{figure.caption.1}{}}
\newlabel{sub@fig:csma_b}{{(b)}{8}{CSMA/CA operation\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces CSMA/CA operation in $\text  {WLAN}_{\text  {A}}$ and $\text  {WLAN}_{\text  {B}}$. $\text  {STA}_{\text  {A}}$ starts a transmission to $\text  {AP}_{\text  {A}}$, since its backoff counter reaches zero first. After that, a collision occurs due to simultaneous transmissions held by $\text  {AP}_{\text  {A}}$ and $\text  {AP}_{\text  {B}}$.\relax }}{8}{figure.caption.1}}
\newlabel{fig:csma}{{1}{8}{CSMA/CA operation in $\text {WLAN}_{\text {A}}$ and $\text {WLAN}_{\text {B}}$. $\text {STA}_{\text {A}}$ starts a transmission to $\text {AP}_{\text {A}}$, since its backoff counter reaches zero first. After that, a collision occurs due to simultaneous transmissions held by $\text {AP}_{\text {A}}$ and $\text {AP}_{\text {B}}$.\relax }{figure.caption.1}{}}
\citation{fwilhelmi2018code}
\newlabel{fig:three_wlans_ctmn_a}{{2(a)}{9}{Scenario with overlapping WLANs\relax }{figure.caption.2}{}}
\newlabel{sub@fig:three_wlans_ctmn_a}{{(a)}{9}{Scenario with overlapping WLANs\relax }{figure.caption.2}{}}
\newlabel{fig:three_wlans_ctmn_b}{{2(b)}{9}{Markov chain\relax }{figure.caption.2}{}}
\newlabel{sub@fig:three_wlans_ctmn_b}{{(b)}{9}{Markov chain\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Toy scenario. WLANs A and C operate in channel 1 while B operates in channel 2. Note that C is in the carrier-sense range of A. Only the transition rate pairs ($\lambda , \mu $) between states $s_1$, $s_2$, $s_3$ and $s_4$ are displayed for the sake of visualization. The states where C may lose packets because of the interference from A are displayed in yellow. Unidirectional backward transitions are show in red.\relax }}{9}{figure.caption.2}}
\newlabel{fig:three_wlans_ctmn}{{2}{9}{Toy scenario. WLANs A and C operate in channel 1 while B operates in channel 2. Note that C is in the carrier-sense range of A. Only the transition rate pairs ($\lambda , \mu $) between states $s_1$, $s_2$, $s_3$ and $s_4$ are displayed for the sake of visualization. The states where C may lose packets because of the interference from A are displayed in yellow. Unidirectional backward transitions are show in red.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Analysis}{9}{subsection.3.3}}
\newlabel{section:spatial_reuse_enhancement}{{3.3}{9}{Analysis}{subsection.3.3}{}}
\newlabel{fig:s1_interactions}{{3(a)}{10}{Scenario 1\relax }{figure.caption.3}{}}
\newlabel{sub@fig:s1_interactions}{{(a)}{10}{Scenario 1\relax }{figure.caption.3}{}}
\newlabel{fig:s2_interactions}{{3(b)}{10}{Scenario 2\relax }{figure.caption.3}{}}
\newlabel{sub@fig:s2_interactions}{{(b)}{10}{Scenario 2\relax }{figure.caption.3}{}}
\newlabel{fig:s3_interactions}{{3(c)}{10}{Scenario 3\relax }{figure.caption.3}{}}
\newlabel{sub@fig:s3_interactions}{{(c)}{10}{Scenario 3\relax }{figure.caption.3}{}}
\newlabel{tbl:configurations}{{3(d)}{10}{Table with possible configurations to be chosen by WLANs\relax }{figure.caption.3}{}}
\newlabel{sub@tbl:configurations}{{(d)}{10}{Table with possible configurations to be chosen by WLANs\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Scenarios for characterizing inter-WLAN interactions.\relax }}{10}{figure.caption.3}}
\newlabel{fig:scenarios_validations}{{3}{10}{Scenarios for characterizing inter-WLAN interactions.\relax }{figure.caption.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Performance in each scenario achieved through different configurations. Each cell contains the performance computed by using CTMNs and Komondor, respectively. Komondor results are extracted from 1,000 s simulations.\relax }}{11}{table.caption.4}}
\newlabel{tbl:results_sr_improvements}{{1}{11}{Performance in each scenario achieved through different configurations. Each cell contains the performance computed by using CTMNs and Komondor, respectively. Komondor results are extracted from 1,000 s simulations.\relax }{table.caption.4}{}}
\citation{akella2007self}
\citation{auer1995gambling}
\@writefile{toc}{\contentsline {section}{\numberline {4}Multi-Armed Bandits for Decentralized Spatial Reuse}{12}{section.4}}
\newlabel{section:mabs}{{4}{12}{Multi-Armed Bandits for Decentralized Spatial Reuse}{section.4}{}}
\citation{auer2002finite,audibert2009exploration,scott2010modern}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Effects of TPC and CST adjustment.\relax }}{13}{table.caption.5}}
\newlabel{tbl:cca_tpc_effects}{{2}{13}{Effects of TPC and CST adjustment.\relax }{table.caption.5}{}}
\newlabel{fig:agents_a}{{4(a)}{14}{WLANs with agents\relax }{figure.caption.6}{}}
\newlabel{sub@fig:agents_a}{{(a)}{14}{WLANs with agents\relax }{figure.caption.6}{}}
\newlabel{fig:agents_b}{{4(b)}{14}{Learning procedure\relax }{figure.caption.6}{}}
\newlabel{sub@fig:agents_b}{{(b)}{14}{Learning procedure\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Agents integration in WLANs. (a) Scenario with two potentially overlapping WLANs, (b) Learning procedure followed by agents according to the performance observed in their associated WLAN.\relax }}{14}{figure.caption.6}}
\newlabel{fig:agents}{{4}{14}{Agents integration in WLANs. (a) Scenario with two potentially overlapping WLANs, (b) Learning procedure followed by agents according to the performance observed in their associated WLAN.\relax }{figure.caption.6}{}}
\citation{wilhelmi2017collaborative}
\citation{thompson1933likelihood}
\citation{agrawal2013further}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Thompson Sampling}{15}{subsection.4.1}}
\newlabel{subsection:thompson_sampling}{{4.1}{15}{Thompson Sampling}{subsection.4.1}{}}
\citation{wilhelmi2017collaborative}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Implementation of MABs (Thompson sampling) in a WLAN\relax }}{16}{algocf.1}}
\newlabel{alg:thompsons}{{1}{16}{Thompson Sampling}{algocf.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Selfish Reward}{16}{subsubsection.4.1.1}}
\newlabel{subsubsection:selfish_learning}{{4.1.1}{16}{Selfish Reward}{subsubsection.4.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Environment-Aware Reward}{17}{subsubsection.4.1.2}}
\newlabel{subsubsection:informed_learning}{{4.1.2}{17}{Environment-Aware Reward}{subsubsection.4.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Considerations of Decentralized Learning in WLANs}{17}{subsection.4.2}}
\newlabel{subsection:considerations}{{4.2}{17}{Considerations of Decentralized Learning in WLANs}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Reward Definition}{19}{subsubsection.4.2.1}}
\newlabel{subsubsection:reward}{{4.2.1}{19}{Reward Definition}{subsubsection.4.2.1}{}}
\newlabel{fig:selfish_s3}{{5(a)}{20}{Scenario\relax }{figure.caption.8}{}}
\newlabel{sub@fig:selfish_s3}{{(a)}{20}{Scenario\relax }{figure.caption.8}{}}
\newlabel{fig:approx_vs_actual_regret}{{5(b)}{20}{Average regret\relax }{figure.caption.8}{}}
\newlabel{sub@fig:approx_vs_actual_regret}{{(b)}{20}{Average regret\relax }{figure.caption.8}{}}
\newlabel{fig:approx_vs_actual_tpt}{{5(c)}{20}{Temporal throughput\relax }{figure.caption.8}{}}
\newlabel{sub@fig:approx_vs_actual_tpt}{{(c)}{20}{Temporal throughput\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Upper bound reward considerations when applying selfish Thompson sampling (100 iterations are considered). (a) Scenario with two asymmetric WLANs in terms of maximum capacity, (b) Temporal regret experienced by each WLAN when the actual upper bound reward (UBR) is known (blue) or not (red), (c) Temporal throughput experienced by each WLAN when the actual UBR is known (blue) or not (red).\relax }}{20}{figure.caption.8}}
\newlabel{fig:actual_vs_approximated_reward}{{5}{20}{Upper bound reward considerations when applying selfish Thompson sampling (100 iterations are considered). (a) Scenario with two asymmetric WLANs in terms of maximum capacity, (b) Temporal regret experienced by each WLAN when the actual upper bound reward (UBR) is known (blue) or not (red), (c) Temporal throughput experienced by each WLAN when the actual UBR is known (blue) or not (red).\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Neighbors Identification when Applying an Environment-Aware Reward}{20}{subsubsection.4.2.2}}
\newlabel{subsubsection:clustering}{{4.2.2}{20}{Neighbors Identification when Applying an Environment-Aware Reward}{subsubsection.4.2.2}{}}
\newlabel{fig:informed_s1}{{6(a)}{21}{Scenario\relax }{figure.caption.9}{}}
\newlabel{sub@fig:informed_s1}{{(a)}{21}{Scenario\relax }{figure.caption.9}{}}
\newlabel{fig:clustering_benefits}{{6(b)}{21}{Individual throughput\relax }{figure.caption.9}{}}
\newlabel{sub@fig:clustering_benefits}{{(b)}{21}{Individual throughput\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Neighbors establishment considerations when applying environment-aware Thompson sampling (100 iterations are considered). (a) Scenario with two independent WLANs in terms of interference, (b) Temporal throughput experienced by each WLAN when using long-range (blue) and short-range clustering (red).\relax }}{21}{figure.caption.9}}
\newlabel{fig:clustering}{{6}{21}{Neighbors establishment considerations when applying environment-aware Thompson sampling (100 iterations are considered). (a) Scenario with two independent WLANs in terms of interference, (b) Temporal throughput experienced by each WLAN when using long-range (blue) and short-range clustering (red).\relax }{figure.caption.9}{}}
\newlabel{fig:informed_s2}{{7(a)}{22}{Scenario\relax }{figure.caption.10}{}}
\newlabel{sub@fig:informed_s2}{{(a)}{22}{Scenario\relax }{figure.caption.10}{}}
\newlabel{fig:clustering_additive_interference}{{7(b)}{22}{Average throughput\relax }{figure.caption.10}{}}
\newlabel{sub@fig:clustering_additive_interference}{{(b)}{22}{Average throughput\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Issues on neighbors establishment when applying environment-aware Thompson sampling (1,000 iterations are considered). (a) Scenario in which $\text  {WLAN}_\text  {B}$ is prone to suffer from flow starvation, (b) Average throughput per WLAN when using long-range (yellow) and short-range clustering (purple). The standard deviation of the average throughput between iterations is shown in red, and the black dashed line indicates the shared goal.\relax }}{22}{figure.caption.10}}
\newlabel{fig:clustering_issues}{{7}{22}{Issues on neighbors establishment when applying environment-aware Thompson sampling (1,000 iterations are considered). (a) Scenario in which $\text {WLAN}_\text {B}$ is prone to suffer from flow starvation, (b) Average throughput per WLAN when using long-range (yellow) and short-range clustering (purple). The standard deviation of the average throughput between iterations is shown in red, and the black dashed line indicates the shared goal.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Learning in Dynamic WLANs}{22}{subsubsection.4.2.3}}
\citation{hartland2006multi}
\citation{gupta2011thompson}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Thompson sampling application in a dynamic scenario where $\text  {WLAN}_\text  {B}$ appears in iteration 500 (1,000 iterations are considered). The black dashed line indicates the shared goal.\relax }}{23}{figure.caption.11}}
\newlabel{fig:dynamic_wlan}{{8}{23}{Thompson sampling application in a dynamic scenario where $\text {WLAN}_\text {B}$ appears in iteration 500 (1,000 iterations are considered). The black dashed line indicates the shared goal.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Performance Evaluation}{23}{section.5}}
\newlabel{section:performance_evaluation}{{5}{23}{Performance Evaluation}{section.5}{}}
\citation{auer2002finite}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Selfish vs Environment-Aware Learning}{24}{subsection.5.1}}
\newlabel{subsection:selfish_vs_informed}{{5.1}{24}{Selfish vs Environment-Aware Learning}{subsection.5.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Learning in Presence of Asymmetries}{24}{subsubsection.5.1.1}}
\newlabel{subsubsection:fairness}{{5.1.1}{24}{Learning in Presence of Asymmetries}{subsubsection.5.1.1}{}}
\newlabel{fig:s1_new}{{9(a)}{25}{Scenario\relax }{figure.caption.12}{}}
\newlabel{sub@fig:s1_new}{{(a)}{25}{Scenario\relax }{figure.caption.12}{}}
\newlabel{fig:scenario_1_new}{{9(b)}{25}{Mean throughput\relax }{figure.caption.12}{}}
\newlabel{sub@fig:scenario_1_new}{{(b)}{25}{Mean throughput\relax }{figure.caption.12}{}}
\newlabel{fig:experiment_2_1_variability}{{9(c)}{25}{Throughput $\text {WLAN}_\text {A}$\relax }{figure.caption.12}{}}
\newlabel{sub@fig:experiment_2_1_variability}{{(c)}{25}{Throughput $\text {WLAN}_\text {A}$\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Fairness issues in both selfish and environment-aware Thompson sampling (10,000 iterations are considered). (a) Scenario in which $\text  {WLAN}_\text  {B}$ is prone to suffer from starvation, (b) Average throughput per WLAN for selfish and environment-aware learning, both for Thompson sampling (TS) and $\varepsilon $-greedy. The standard deviation of the average throughput between iterations is shown in red. The pink and green dashed lines indicate the maximum performance achieved per WLAN regarding both selfish and environment-aware optimal solutions, respectively. (c) Temporal throughput achieved by $\text  {WLAN}_\text  {A}$ when learning selfishly through Thompson sampling and $\varepsilon $-greedy, respectively.\relax }}{25}{figure.caption.12}}
\newlabel{fig:selfish_learning_fairness_issue}{{9}{25}{Fairness issues in both selfish and environment-aware Thompson sampling (10,000 iterations are considered). (a) Scenario in which $\text {WLAN}_\text {B}$ is prone to suffer from starvation, (b) Average throughput per WLAN for selfish and environment-aware learning, both for Thompson sampling (TS) and $\varepsilon $-greedy. The standard deviation of the average throughput between iterations is shown in red. The pink and green dashed lines indicate the maximum performance achieved per WLAN regarding both selfish and environment-aware optimal solutions, respectively. (c) Temporal throughput achieved by $\text {WLAN}_\text {A}$ when learning selfishly through Thompson sampling and $\varepsilon $-greedy, respectively.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Learning on Equal Terms}{25}{subsubsection.5.1.2}}
\newlabel{subsubsection:resources_maximization}{{5.1.2}{25}{Learning on Equal Terms}{subsubsection.5.1.2}{}}
\newlabel{fig:selfish_s1}{{10(a)}{26}{Scenario\relax }{figure.caption.13}{}}
\newlabel{sub@fig:selfish_s1}{{(a)}{26}{Scenario\relax }{figure.caption.13}{}}
\newlabel{fig:4_grid_selfish_benefits_mean_tpt}{{10(b)}{26}{Mean individual throughput\relax }{figure.caption.13}{}}
\newlabel{sub@fig:4_grid_selfish_benefits_mean_tpt}{{(b)}{26}{Mean individual throughput\relax }{figure.caption.13}{}}
\newlabel{fig:experiment_2_2_variability}{{10(c)}{26}{Throughput $\text {WLAN}_\text {A}$\relax }{figure.caption.13}{}}
\newlabel{sub@fig:experiment_2_2_variability}{{(c)}{26}{Throughput $\text {WLAN}_\text {A}$\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Potential of both selfish and environment-aware Thompson sampling (10,000 iterations are considered). (a) Scenario in which STAs are placed conservatively regarding inter-WLAN interference, (b) Average throughput per WLAN for Selfish and Environment-aware learning, both for Thompson sampling (TS) and $\varepsilon $-greedy. The standard deviation of the average throughput between iterations is shown in red. The pink and green dashed lines indicate the maximum performance achieved per WLAN regarding both selfish and environment-aware optimal solutions, respectively. (c) Temporal throughput achieved by $\text  {WLAN}_\text  {A}$ when learning selfishly through Thompson sampling and $\varepsilon $-greedy, respectively.\relax }}{26}{figure.caption.13}}
\newlabel{fig:4_grid_selfish_benefits}{{10}{26}{Potential of both selfish and environment-aware Thompson sampling (10,000 iterations are considered). (a) Scenario in which STAs are placed conservatively regarding inter-WLAN interference, (b) Average throughput per WLAN for Selfish and Environment-aware learning, both for Thompson sampling (TS) and $\varepsilon $-greedy. The standard deviation of the average throughput between iterations is shown in red. The pink and green dashed lines indicate the maximum performance achieved per WLAN regarding both selfish and environment-aware optimal solutions, respectively. (c) Temporal throughput achieved by $\text {WLAN}_\text {A}$ when learning selfishly through Thompson sampling and $\varepsilon $-greedy, respectively.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Competition Effects}{26}{subsubsection.5.1.3}}
\newlabel{subsubsection:competition}{{5.1.3}{26}{Competition Effects}{subsubsection.5.1.3}{}}
\newlabel{fig:adversarial_issues_scenario}{{11(a)}{27}{Scenario\relax }{figure.caption.14}{}}
\newlabel{sub@fig:adversarial_issues_scenario}{{(a)}{27}{Scenario\relax }{figure.caption.14}{}}
\newlabel{fig:4_grid_selfish_adversarial_mean_tpt}{{11(b)}{27}{Mean individual throughput\relax }{figure.caption.14}{}}
\newlabel{sub@fig:4_grid_selfish_adversarial_mean_tpt}{{(b)}{27}{Mean individual throughput\relax }{figure.caption.14}{}}
\newlabel{fig:experiment_2_3_variability}{{11(c)}{27}{Throughput $\text {WLAN}_\text {A}$\relax }{figure.caption.14}{}}
\newlabel{sub@fig:experiment_2_3_variability}{{(c)}{27}{Throughput $\text {WLAN}_\text {A}$\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Competition issues in both selfish and environment-aware Thompson sampling (10,000 iterations are considered). (a) Scenario in which STAs are placed in a greedy way regarding inter-WLAN interference, (b) Average throughput per WLAN for Selfish and Environment-aware learning, both for Thompson sampling (TS) and $\varepsilon $-greedy. The standard deviation of the average throughput between iterations is shown in red. The pink and green dashed lines indicate the maximum performance achieved per WLAN regarding both selfish and environment-aware optimal solutions, respectively. (c) Temporal throughput achieved by $\text  {WLAN}_\text  {A}$ when learning selfishly through Thompson sampling and $\varepsilon $-greedy, respectively.\relax }}{27}{figure.caption.14}}
\newlabel{fig:4_grid_selfish_adversarial}{{11}{27}{Competition issues in both selfish and environment-aware Thompson sampling (10,000 iterations are considered). (a) Scenario in which STAs are placed in a greedy way regarding inter-WLAN interference, (b) Average throughput per WLAN for Selfish and Environment-aware learning, both for Thompson sampling (TS) and $\varepsilon $-greedy. The standard deviation of the average throughput between iterations is shown in red. The pink and green dashed lines indicate the maximum performance achieved per WLAN regarding both selfish and environment-aware optimal solutions, respectively. (c) Temporal throughput achieved by $\text {WLAN}_\text {A}$ when learning selfishly through Thompson sampling and $\varepsilon $-greedy, respectively.\relax }{figure.caption.14}{}}
\citation{akella2007self}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Random Scenarios}{28}{subsection.5.2}}
\newlabel{section:scalability}{{5.2}{28}{Random Scenarios}{subsection.5.2}{}}
\newlabel{fig:scalability_mean_tpt}{{12(a)}{29}{Average throughput\relax }{figure.caption.15}{}}
\newlabel{sub@fig:scalability_mean_tpt}{{(a)}{29}{Average throughput\relax }{figure.caption.15}{}}
\newlabel{fig:scalability_mean_maxmin}{{12(b)}{29}{Max-min throughput\relax }{figure.caption.15}{}}
\newlabel{sub@fig:scalability_mean_maxmin}{{(b)}{29}{Max-min throughput\relax }{figure.caption.15}{}}
\newlabel{fig:scalability_mean_jfi}{{12(c)}{29}{Throughput JFI\relax }{figure.caption.15}{}}
\newlabel{sub@fig:scalability_mean_jfi}{{(c)}{29}{Throughput JFI\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Average results of applying 500-iteration Thompson sampling in 50 random scenarios for \{2, 4, 6, 8\} potentially overlapping WLANs. (a) Mean average throughput with standard deviation (in red) per WLAN in each scenario when using static (purple), selfish learning (yellow) or environment-aware learning (green), (b) Mean average max-min throughput with standard deviation (in red) per WLAN in each scenario when using static (purple), selfish learning (yellow) or environment-aware learning (green), (c) Mean JFI with standard deviation (in red) in each scenario when using static (purple), selfish learning (yellow) or environment-aware learning (green)\relax }}{29}{figure.caption.15}}
\newlabel{fig:scalability_results}{{12}{29}{Average results of applying 500-iteration Thompson sampling in 50 random scenarios for \{2, 4, 6, 8\} potentially overlapping WLANs. (a) Mean average throughput with standard deviation (in red) per WLAN in each scenario when using static (purple), selfish learning (yellow) or environment-aware learning (green), (b) Mean average max-min throughput with standard deviation (in red) per WLAN in each scenario when using static (purple), selfish learning (yellow) or environment-aware learning (green), (c) Mean JFI with standard deviation (in red) in each scenario when using static (purple), selfish learning (yellow) or environment-aware learning (green)\relax }{figure.caption.15}{}}
\newlabel{fig:scalability_selfish_accumulated}{{13(a)}{29}{Selfish\relax }{figure.caption.16}{}}
\newlabel{sub@fig:scalability_selfish_accumulated}{{(a)}{29}{Selfish\relax }{figure.caption.16}{}}
\newlabel{fig:scalability_informed_accumulated}{{13(b)}{29}{Environment-aware\relax }{figure.caption.16}{}}
\newlabel{sub@fig:scalability_informed_accumulated}{{(b)}{29}{Environment-aware\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Mean average throughput with standard deviation achieved during specific intervals. 500 iterations are considered for both selfish and environment-aware Thompson sampling in 50 random scenarios for \{2, 4, 6, 8\} overlapping WLANs. (a) Results for the selfish strategy, (b) Results for the environment-aware strategy.\relax }}{29}{figure.caption.16}}
\newlabel{fig:cumulative_tpt}{{13}{29}{Mean average throughput with standard deviation achieved during specific intervals. 500 iterations are considered for both selfish and environment-aware Thompson sampling in 50 random scenarios for \{2, 4, 6, 8\} overlapping WLANs. (a) Results for the selfish strategy, (b) Results for the environment-aware strategy.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{30}{section.6}}
\newlabel{section:conclusions}{{6}{30}{Conclusions}{section.6}{}}
\citation{merlin2015tgax}
\citation{ieee2015qam}
\citation{tgax2017draft}
\@writefile{toc}{\contentsline {section}{Appendices}{31}{section*.18}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Wireless Environment}{31}{Appendix .1.A}}
\newlabel{section:simulated_wireless_environment}{{A}{31}{Wireless Environment}{Appendix .1.A}{}}
\bibdata{references}
\bibcite{ieee2015qam}{{1}{2015}{{iee}}{{}}}
\bibcite{tgax2017draft}{{2}{September 2017}{{tga}}{{}}}
\bibcite{agrawal2013further}{{3}{2013}{{Agrawal and Goyal}}{{}}}
\bibcite{akella2007self}{{4}{2007}{{Akella et~al.}}{{Akella, Judd, Seshan, and Steenkiste}}}
\bibcite{anandkumar2011distributed}{{5}{2011}{{Anandkumar et~al.}}{{Anandkumar, Michael, Tang, and Swami}}}
\bibcite{audibert2009exploration}{{6}{2009}{{Audibert et~al.}}{{Audibert, Munos, and Szepesv{\'a}ri}}}
\bibcite{auer1995gambling}{{7}{1995}{{Auer et~al.}}{{Auer, Cesa-Bianchi, Freund, and Schapire}}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Simulation parameters\relax }}{32}{table.caption.19}}
\newlabel{tbl:simulation_parameters}{{3}{32}{Simulation parameters\relax }{table.caption.19}{}}
\bibcite{auer2002finite}{{8}{2002}{{Auer et~al.}}{{Auer, Cesa-Bianchi, and Fischer}}}
\bibcite{barrachina2018overlap}{{9}{2018{a}}{{Barrachina-Mu{\~n}oz et~al.}}{{Barrachina-Mu{\~n}oz, Wilhelmi, and Bellalta}}}
\bibcite{barrachina2018performance}{{10}{2018{b}}{{Barrachina-Mu{\~n}oz et~al.}}{{Barrachina-Mu{\~n}oz, Wilhelmi, and Bellalta}}}
\bibcite{bellalta2016ax}{{11}{2016}{{Bellalta}}{{}}}
\bibcite{bellalta2017throughput}{{12}{2017}{{Bellalta}}{{}}}
\bibcite{bennis2010q}{{13}{2010}{{Bennis and Niyato}}{{}}}
\bibcite{bennis2011distributed}{{14}{2011}{{Bennis et~al.}}{{Bennis, Guruacharya, and Niyato}}}
\bibcite{chen2010distributed}{{15}{2010}{{Chen}}{{}}}
\bibcite{ergin2007understanding}{{16}{2007}{{Ergin et~al.}}{{Ergin, Ramachandran, and Gruteser}}}
\bibcite{gupta2011thompson}{{17}{2011}{{Gupta et~al.}}{{Gupta, Granmo, and Agrawala}}}
\bibcite{hartland2006multi}{{18}{2006}{{Hartland et~al.}}{{Hartland, Gelly, Baskiotis, Teytaud, and Sebag}}}
\bibcite{li2009multi}{{19}{2009}{{Li}}{{}}}
\bibcite{liu2010distributed}{{20}{2010}{{Liu and Zhao}}{{}}}
\bibcite{maghsudi2015channel}{{21}{2015{a}}{{Maghsudi and Sta{\'n}czak}}{{}}}
\bibcite{maghsudi2015joint}{{22}{2015{b}}{{Maghsudi and Sta{\'n}czak}}{{}}}
\bibcite{merlin2015tgax}{{23}{2015}{{Merlin et~al.}}{{Merlin, Barriac, Sampath, Cariou, Derham, Le~Rouzic, Stacey, Park, Porat, Jindal, et~al.}}}
\bibcite{nie1999q}{{24}{1999}{{Nie and Haykin}}{{}}}
\bibcite{rosenski2016multi}{{25}{2016}{{Rosenski et~al.}}{{Rosenski, Shamir, and Szlak}}}
\bibcite{rupasinghe2015reinforcement}{{26}{2015}{{Rupasinghe and G{\"u}ven{\c {c}}}}{{}}}
\bibcite{sallent2015learning}{{27}{2015}{{Sallent et~al.}}{{Sallent, P{\'e}rez-Romero, Ferr{\'u}s, and Agust{\'\i }}}}
\bibcite{scott2010modern}{{28}{2010}{{Scott}}{{}}}
\bibcite{smith2015dynamic}{{29}{2015}{{Smith}}{{}}}
\bibcite{thompson1933likelihood}{{30}{1933}{{Thompson}}{{}}}
\bibcite{fwilhelmi2018code}{{31}{2018}{{Wilhelmi}}{{}}}
\bibcite{wilhelmi2017collaborative}{{32}{2017}{{Wilhelmi et~al.}}{{Wilhelmi, Bellalta, Cano, Jonsson, Neu, and Barrachina-Mu{\~n}oz}}}
